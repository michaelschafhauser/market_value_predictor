{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1793bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53334df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc7f2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from market_value_predictor.preproc import manual_encoding, reduce_number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c670b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bcdce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../raw_data/master_df_with_webscraping.csv\")\n",
    "df_train = pd.read_csv(\"../../raw_data/master_data_train.csv\").drop(columns=\"Unnamed: 0\")\n",
    "df_test = pd.read_csv(\"../../raw_data/master_data_test.csv\").drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfac6c0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a0d9d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 {color: black;background-color: white;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 pre{padding: 0;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-toggleable {background-color: white;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-estimator:hover {background-color: #d4ebff;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-item {z-index: 1;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-parallel-item:only-child::after {width: 0;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-5362bb4f-0524-4848-ba5d-ea9339f2e585 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-5362bb4f-0524-4848-ba5d-ea9339f2e585\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"991e5a63-aa45-45fb-8359-dc225926fa65\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"991e5a63-aa45-45fb-8359-dc225926fa65\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('player_traits',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cbdc0>)),\n",
       "                ('player_tags',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cbe50>)),\n",
       "                ('player_positions',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cbee0>)),\n",
       "                ('nationality',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cb940>)),\n",
       "                ('league_name',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b1899f280>)),\n",
       "                ('drop_nas',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b18a43820>))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"654db674-a4f4-4c6f-a4a8-880cb7046459\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"654db674-a4f4-4c6f-a4a8-880cb7046459\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x7f6b189cbdc0>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"22b738ae-f31c-4e28-9e11-7862fe00a0a7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"22b738ae-f31c-4e28-9e11-7862fe00a0a7\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x7f6b189cbe50>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5d897783-9d11-468b-b6a6-184374495ac5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5d897783-9d11-468b-b6a6-184374495ac5\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x7f6b189cbee0>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a0a3cd23-eb9c-48d0-9e48-ce4b9aeef301\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a0a3cd23-eb9c-48d0-9e48-ce4b9aeef301\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x7f6b189cb940>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4b470ebf-519c-4dfe-8234-be8159d6bc54\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4b470ebf-519c-4dfe-8234-be8159d6bc54\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x7f6b1899f280>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9b8bd376-b1cd-4987-81f0-c7ca5c8dca5d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9b8bd376-b1cd-4987-81f0-c7ca5c8dca5d\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x7f6b18a43820>)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('player_traits',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cbdc0>)),\n",
       "                ('player_tags',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cbe50>)),\n",
       "                ('player_positions',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cbee0>)),\n",
       "                ('nationality',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b189cb940>)),\n",
       "                ('league_name',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b1899f280>)),\n",
       "                ('drop_nas',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6b18a43820>))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "drop_nas = FunctionTransformer(lambda df: df.dropna(subset=list(df.select_dtypes(object).columns)))\n",
    "\n",
    "feat_eng_player_traits = FunctionTransformer(lambda df: manual_encoding(df, \"player_traits\"))\n",
    "feat_eng_player_tags = FunctionTransformer(lambda df: manual_encoding(df, \"player_tags\"))\n",
    "feat_eng_player_positions = FunctionTransformer(lambda df: manual_encoding(df, \"player_positions\"))\n",
    "\n",
    "dim_reduction_nationality = FunctionTransformer(lambda df: reduce_number_of_classes(df, \"nationality\", 50))\n",
    "dim_reduction_league_name = FunctionTransformer(lambda df: reduce_number_of_classes(df, \"league_name\", 100))\n",
    "\n",
    "cluster_team_position = FunctionTransformer(lambda df: cluster_team_position(df))\n",
    "\n",
    "feat_eng = Pipeline([\n",
    "    (\"player_traits\", feat_eng_player_traits),\n",
    "    (\"player_tags\", feat_eng_player_tags),\n",
    "    (\"player_positions\", feat_eng_player_positions),\n",
    "    (\"nationality\", dim_reduction_nationality),\n",
    "    (\"league_name\", dim_reduction_league_name),\n",
    "    (\"drop_nas\", drop_nas),\n",
    "#     (\"team_position\", cluster_team_position)\n",
    "])\n",
    "\n",
    "feat_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7b08fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transformed = feat_eng.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d52b65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_transformed = feat_eng.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286dfb71",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261fb06",
   "metadata": {},
   "source": [
    "## Define lists of columns for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "573c1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cats = list(df_train.select_dtypes(object).columns)\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "all_numerics = list(df_train.select_dtypes(include=numerics).columns)\n",
    "\n",
    "all_numerics.remove(\"fee_cleaned\")\n",
    "\n",
    "encoded_columns = [elem for elem in all_numerics if \"player_tags_\" in elem] + [\n",
    "    elem for elem in all_numerics if \"player_positions_\" in elem\n",
    "] + [elem for elem in all_numerics if \"player_traits_\" in elem]\n",
    "\n",
    "all_numerics_wo_encoded = []\n",
    "for elem in all_numerics:\n",
    "    if elem not in encoded_columns:\n",
    "        all_numerics_wo_encoded.append(elem)\n",
    "\n",
    "numericals_zero_impute = [\n",
    "    \"gk_diving\", \"gk_handling\", \"gk_kicking\", \"gk_reflexes\", \"gk_speed\",\n",
    "    \"gk_positioning\", \"release_clause_eur\"\n",
    "]\n",
    "\n",
    "numericals_mean_impute = []\n",
    "\n",
    "for elem in all_numerics_wo_encoded:\n",
    "    if elem not in numericals_zero_impute:\n",
    "        numericals_mean_impute.append(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da70b62",
   "metadata": {},
   "source": [
    "## Define transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4cf07088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "cachedir = mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84f7a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_tr = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "num_mean_tr = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "cat_tr = OneHotEncoder(handle_unknown='ignore', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52565481",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "886b6826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d {color: black;background-color: white;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d pre{padding: 0;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-toggleable {background-color: white;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-estimator:hover {background-color: #d4ebff;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-item {z-index: 1;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-parallel-item:only-child::after {width: 0;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-4230933c-6d78-4fda-8e32-a384f20a2e3d div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-4230933c-6d78-4fda-8e32-a384f20a2e3d\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"11b4c4b3-7fb9-44e6-8c68-2d01fd3bab16\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"11b4c4b3-7fb9-44e6-8c68-2d01fd3bab16\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory='/tmp/tmpugcxxij0',\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerics_zero_imputing',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['gk_diving', 'gk_handling',\n",
       "                                                   'gk_kicking', 'gk_reflexes',\n",
       "                                                   'gk_speed', 'gk_positioning',\n",
       "                                                   'release_clause_eur']),...\n",
       "                                                   'skill_long_passing',\n",
       "                                                   'skill_ball_control',\n",
       "                                                   'movement_acceleration',\n",
       "                                                   'movement_sprint_speed',\n",
       "                                                   'movement_agility', ...]),\n",
       "                                                 ('cat_tr',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['nationality', 'club_name',\n",
       "                                                   'league_name',\n",
       "                                                   'player_positions',\n",
       "                                                   'preferred_foot',\n",
       "                                                   'work_rate', 'body_type',\n",
       "                                                   'real_face', 'player_tags',\n",
       "                                                   'team_position',\n",
       "                                                   'player_traits'])])),\n",
       "                ('regressor', ElasticNet())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"edd710ec-c6da-4060-8133-eb2d908065f7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"edd710ec-c6da-4060-8133-eb2d908065f7\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('numerics_zero_imputing',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('scaler', MinMaxScaler())]),\n",
       "                                 ['gk_diving', 'gk_handling', 'gk_kicking',\n",
       "                                  'gk_reflexes', 'gk_speed', 'gk_positioning',\n",
       "                                  'release_clause_eur']),\n",
       "                                ('numerics_mean_imputing',\n",
       "                                 Pipeline(steps=[('imputer', Simple...\n",
       "                                  'skill_curve', 'skill_fk_accuracy',\n",
       "                                  'skill_long_passing', 'skill_ball_control',\n",
       "                                  'movement_acceleration',\n",
       "                                  'movement_sprint_speed', 'movement_agility', ...]),\n",
       "                                ('cat_tr',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['nationality', 'club_name', 'league_name',\n",
       "                                  'player_positions', 'preferred_foot',\n",
       "                                  'work_rate', 'body_type', 'real_face',\n",
       "                                  'player_tags', 'team_position',\n",
       "                                  'player_traits'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e2ba047d-f1ff-4bfa-a2bb-65dfa5a6ab33\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e2ba047d-f1ff-4bfa-a2bb-65dfa5a6ab33\">numerics_zero_imputing</label><div class=\"sk-toggleable__content\"><pre>['gk_diving', 'gk_handling', 'gk_kicking', 'gk_reflexes', 'gk_speed', 'gk_positioning', 'release_clause_eur']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c7f27ad5-adc0-4d9c-9037-b1531c3efafb\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c7f27ad5-adc0-4d9c-9037-b1531c3efafb\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"95ca1905-b479-4df4-809b-54f115938162\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"95ca1905-b479-4df4-809b-54f115938162\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c517e22c-6781-4604-82a7-bfd1c14ae557\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c517e22c-6781-4604-82a7-bfd1c14ae557\">numerics_mean_imputing</label><div class=\"sk-toggleable__content\"><pre>['age', 'height_cm', 'weight_kg', 'league_rank', 'overall', 'potential', 'wage_eur', 'international_reputation', 'weak_foot', 'skill_moves', 'team_jersey_number', 'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', 'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control', 'movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure', 'defending_marking', 'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning', 'goalkeeping_reflexes', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'fifa year', 'national_team', 'seasons_with_club', 'on_loan', 'remaining_seasons_on_contract']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fb3256c4-078a-4064-9367-bb36c3e8db73\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fb3256c4-078a-4064-9367-bb36c3e8db73\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4f283ee1-2f0b-4a74-8bd4-7a96cdc9dd87\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4f283ee1-2f0b-4a74-8bd4-7a96cdc9dd87\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5b8b2d92-362e-4abf-9d8d-120fc96a75be\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5b8b2d92-362e-4abf-9d8d-120fc96a75be\">cat_tr</label><div class=\"sk-toggleable__content\"><pre>['nationality', 'club_name', 'league_name', 'player_positions', 'preferred_foot', 'work_rate', 'body_type', 'real_face', 'player_tags', 'team_position', 'player_traits']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5f7e7592-f8d2-492c-a2fe-9079d16baa8c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5f7e7592-f8d2-492c-a2fe-9079d16baa8c\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3832f550-0971-485f-ade8-f24af911cb0c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3832f550-0971-485f-ade8-f24af911cb0c\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1b83cc7b-2544-4b0d-a1c3-9ddc7a94b26a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1b83cc7b-2544-4b0d-a1c3-9ddc7a94b26a\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"09efc46f-e439-4cf9-ad1f-e143c93722dc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"09efc46f-e439-4cf9-ad1f-e143c93722dc\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory='/tmp/tmpugcxxij0',\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerics_zero_imputing',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['gk_diving', 'gk_handling',\n",
       "                                                   'gk_kicking', 'gk_reflexes',\n",
       "                                                   'gk_speed', 'gk_positioning',\n",
       "                                                   'release_clause_eur']),...\n",
       "                                                   'skill_long_passing',\n",
       "                                                   'skill_ball_control',\n",
       "                                                   'movement_acceleration',\n",
       "                                                   'movement_sprint_speed',\n",
       "                                                   'movement_agility', ...]),\n",
       "                                                 ('cat_tr',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['nationality', 'club_name',\n",
       "                                                   'league_name',\n",
       "                                                   'player_positions',\n",
       "                                                   'preferred_foot',\n",
       "                                                   'work_rate', 'body_type',\n",
       "                                                   'real_face', 'player_tags',\n",
       "                                                   'team_position',\n",
       "                                                   'player_traits'])])),\n",
       "                ('regressor', ElasticNet())])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [(\"numerics_zero_imputing\", num_zero_tr, numericals_zero_impute),\n",
    "     (\"numerics_mean_imputing\", num_mean_tr, numericals_mean_impute),\n",
    "     (\"cat_tr\", cat_tr, all_cats), ],\n",
    "remainder=\"passthrough\")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    #(\"feat_eng\", feat_eng),\n",
    "    (\"preprocessing\", preprocessor), \n",
    "    (\"regressor\", ElasticNet())], memory=cachedir)\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858a814",
   "metadata": {},
   "source": [
    "## Train pipeline    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ebc5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=\"fee_cleaned\")\n",
    "y_train = df_train[[\"fee_cleaned\"]]\n",
    "X_test = df_test.drop(columns=\"fee_cleaned\")\n",
    "y_test = df_test[[\"fee_cleaned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "acc6f4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b {color: black;background-color: white;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b pre{padding: 0;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-toggleable {background-color: white;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-estimator:hover {background-color: #d4ebff;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-item {z-index: 1;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-parallel-item:only-child::after {width: 0;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-e8d00975-c54e-4d4c-9e65-7a5680b4d21b\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5b930866-2634-4b05-94c1-bd88ac8ce18a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5b930866-2634-4b05-94c1-bd88ac8ce18a\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory='/tmp/tmpugcxxij0',\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerics_zero_imputing',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['gk_diving', 'gk_handling',\n",
       "                                                   'gk_kicking', 'gk_reflexes',\n",
       "                                                   'gk_speed', 'gk_positioning',\n",
       "                                                   'release_clause_eur']),...\n",
       "                                                   'skill_long_passing',\n",
       "                                                   'skill_ball_control',\n",
       "                                                   'movement_acceleration',\n",
       "                                                   'movement_sprint_speed',\n",
       "                                                   'movement_agility', ...]),\n",
       "                                                 ('cat_tr',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['nationality', 'club_name',\n",
       "                                                   'league_name',\n",
       "                                                   'player_positions',\n",
       "                                                   'preferred_foot',\n",
       "                                                   'work_rate', 'body_type',\n",
       "                                                   'real_face', 'player_tags',\n",
       "                                                   'team_position',\n",
       "                                                   'player_traits'])])),\n",
       "                ('regressor', ElasticNet())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2938bec8-cb79-46e3-8037-105e44c3ba47\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2938bec8-cb79-46e3-8037-105e44c3ba47\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('numerics_zero_imputing',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('scaler', MinMaxScaler())]),\n",
       "                                 ['gk_diving', 'gk_handling', 'gk_kicking',\n",
       "                                  'gk_reflexes', 'gk_speed', 'gk_positioning',\n",
       "                                  'release_clause_eur']),\n",
       "                                ('numerics_mean_imputing',\n",
       "                                 Pipeline(steps=[('imputer', Simple...\n",
       "                                  'skill_curve', 'skill_fk_accuracy',\n",
       "                                  'skill_long_passing', 'skill_ball_control',\n",
       "                                  'movement_acceleration',\n",
       "                                  'movement_sprint_speed', 'movement_agility', ...]),\n",
       "                                ('cat_tr',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['nationality', 'club_name', 'league_name',\n",
       "                                  'player_positions', 'preferred_foot',\n",
       "                                  'work_rate', 'body_type', 'real_face',\n",
       "                                  'player_tags', 'team_position',\n",
       "                                  'player_traits'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a795223e-428a-4b52-aba2-03d942a2e256\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a795223e-428a-4b52-aba2-03d942a2e256\">numerics_zero_imputing</label><div class=\"sk-toggleable__content\"><pre>['gk_diving', 'gk_handling', 'gk_kicking', 'gk_reflexes', 'gk_speed', 'gk_positioning', 'release_clause_eur']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cd190d5c-0f05-47e1-8140-d05bb743e9e7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"cd190d5c-0f05-47e1-8140-d05bb743e9e7\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ad331e10-ddfc-48fa-afae-5c7f90361c04\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ad331e10-ddfc-48fa-afae-5c7f90361c04\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e0c9dd34-e7d3-4915-afcf-bfb42134547b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e0c9dd34-e7d3-4915-afcf-bfb42134547b\">numerics_mean_imputing</label><div class=\"sk-toggleable__content\"><pre>['age', 'height_cm', 'weight_kg', 'league_rank', 'overall', 'potential', 'wage_eur', 'international_reputation', 'weak_foot', 'skill_moves', 'team_jersey_number', 'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', 'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control', 'movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure', 'defending_marking', 'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning', 'goalkeeping_reflexes', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'fifa year', 'national_team', 'seasons_with_club', 'on_loan', 'remaining_seasons_on_contract']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a308448a-f634-4977-b7b6-76e2311c5eeb\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a308448a-f634-4977-b7b6-76e2311c5eeb\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0c1f697f-2994-489b-929d-aafb45a5de8b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0c1f697f-2994-489b-929d-aafb45a5de8b\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"52a8fbc2-5197-439e-a873-35cc9a950170\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"52a8fbc2-5197-439e-a873-35cc9a950170\">cat_tr</label><div class=\"sk-toggleable__content\"><pre>['nationality', 'club_name', 'league_name', 'player_positions', 'preferred_foot', 'work_rate', 'body_type', 'real_face', 'player_tags', 'team_position', 'player_traits']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"48a33e3d-223b-42e5-a4c1-b23bee533841\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"48a33e3d-223b-42e5-a4c1-b23bee533841\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"54393b19-d814-48e1-9f12-25ae1940bd92\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"54393b19-d814-48e1-9f12-25ae1940bd92\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ca64c2b4-9f01-4b98-b7d5-0a68ef582a9b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ca64c2b4-9f01-4b98-b7d5-0a68ef582a9b\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"22726101-9a56-4ccc-a3c6-1d1c913d5aa3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"22726101-9a56-4ccc-a3c6-1d1c913d5aa3\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory='/tmp/tmpugcxxij0',\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerics_zero_imputing',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['gk_diving', 'gk_handling',\n",
       "                                                   'gk_kicking', 'gk_reflexes',\n",
       "                                                   'gk_speed', 'gk_positioning',\n",
       "                                                   'release_clause_eur']),...\n",
       "                                                   'skill_long_passing',\n",
       "                                                   'skill_ball_control',\n",
       "                                                   'movement_acceleration',\n",
       "                                                   'movement_sprint_speed',\n",
       "                                                   'movement_agility', ...]),\n",
       "                                                 ('cat_tr',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['nationality', 'club_name',\n",
       "                                                   'league_name',\n",
       "                                                   'player_positions',\n",
       "                                                   'preferred_foot',\n",
       "                                                   'work_rate', 'body_type',\n",
       "                                                   'real_face', 'player_tags',\n",
       "                                                   'team_position',\n",
       "                                                   'player_traits'])])),\n",
       "                ('regressor', ElasticNet())])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f881c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "51975c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04508533798990666"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3decba6c",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d0cab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"fee_cleaned\")\n",
    "y = df[[\"fee_cleaned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1f3f145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032431296126178656"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X, y, cv=5, scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54b6265f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': '/tmp/tmpugcxxij0',\n",
       " 'steps': [('preprocessing',\n",
       "   ColumnTransformer(remainder='passthrough',\n",
       "                     transformers=[('numerics_zero_imputing',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(fill_value=0,\n",
       "                                                                   strategy='constant')),\n",
       "                                                    ('scaler', MinMaxScaler())]),\n",
       "                                    ['gk_diving', 'gk_handling', 'gk_kicking',\n",
       "                                     'gk_reflexes', 'gk_speed', 'gk_positioning',\n",
       "                                     'release_clause_eur']),\n",
       "                                   ('numerics_mean_imputing',\n",
       "                                    Pipeline(steps=[('imputer', Simple...\n",
       "                                     'skill_curve', 'skill_fk_accuracy',\n",
       "                                     'skill_long_passing', 'skill_ball_control',\n",
       "                                     'movement_acceleration',\n",
       "                                     'movement_sprint_speed', 'movement_agility', ...]),\n",
       "                                   ('cat_tr',\n",
       "                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                    ['nationality', 'club_name', 'league_name',\n",
       "                                     'player_positions', 'preferred_foot',\n",
       "                                     'work_rate', 'body_type', 'real_face',\n",
       "                                     'player_tags', 'team_position',\n",
       "                                     'player_traits'])])),\n",
       "  ('regressor', ElasticNet())],\n",
       " 'verbose': False,\n",
       " 'preprocessing': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('numerics_zero_imputing',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(fill_value=0,\n",
       "                                                                 strategy='constant')),\n",
       "                                                  ('scaler', MinMaxScaler())]),\n",
       "                                  ['gk_diving', 'gk_handling', 'gk_kicking',\n",
       "                                   'gk_reflexes', 'gk_speed', 'gk_positioning',\n",
       "                                   'release_clause_eur']),\n",
       "                                 ('numerics_mean_imputing',\n",
       "                                  Pipeline(steps=[('imputer', Simple...\n",
       "                                   'skill_curve', 'skill_fk_accuracy',\n",
       "                                   'skill_long_passing', 'skill_ball_control',\n",
       "                                   'movement_acceleration',\n",
       "                                   'movement_sprint_speed', 'movement_agility', ...]),\n",
       "                                 ('cat_tr',\n",
       "                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                  ['nationality', 'club_name', 'league_name',\n",
       "                                   'player_positions', 'preferred_foot',\n",
       "                                   'work_rate', 'body_type', 'real_face',\n",
       "                                   'player_tags', 'team_position',\n",
       "                                   'player_traits'])]),\n",
       " 'regressor': ElasticNet(),\n",
       " 'preprocessing__n_jobs': None,\n",
       " 'preprocessing__remainder': 'passthrough',\n",
       " 'preprocessing__sparse_threshold': 0.3,\n",
       " 'preprocessing__transformer_weights': None,\n",
       " 'preprocessing__transformers': [('numerics_zero_imputing',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                   ('scaler', MinMaxScaler())]),\n",
       "   ['gk_diving',\n",
       "    'gk_handling',\n",
       "    'gk_kicking',\n",
       "    'gk_reflexes',\n",
       "    'gk_speed',\n",
       "    'gk_positioning',\n",
       "    'release_clause_eur']),\n",
       "  ('numerics_mean_imputing',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler())]),\n",
       "   ['age',\n",
       "    'height_cm',\n",
       "    'weight_kg',\n",
       "    'league_rank',\n",
       "    'overall',\n",
       "    'potential',\n",
       "    'wage_eur',\n",
       "    'international_reputation',\n",
       "    'weak_foot',\n",
       "    'skill_moves',\n",
       "    'team_jersey_number',\n",
       "    'pace',\n",
       "    'shooting',\n",
       "    'passing',\n",
       "    'dribbling',\n",
       "    'defending',\n",
       "    'physic',\n",
       "    'attacking_crossing',\n",
       "    'attacking_finishing',\n",
       "    'attacking_heading_accuracy',\n",
       "    'attacking_short_passing',\n",
       "    'attacking_volleys',\n",
       "    'skill_dribbling',\n",
       "    'skill_curve',\n",
       "    'skill_fk_accuracy',\n",
       "    'skill_long_passing',\n",
       "    'skill_ball_control',\n",
       "    'movement_acceleration',\n",
       "    'movement_sprint_speed',\n",
       "    'movement_agility',\n",
       "    'movement_reactions',\n",
       "    'movement_balance',\n",
       "    'power_shot_power',\n",
       "    'power_jumping',\n",
       "    'power_stamina',\n",
       "    'power_strength',\n",
       "    'power_long_shots',\n",
       "    'mentality_aggression',\n",
       "    'mentality_interceptions',\n",
       "    'mentality_positioning',\n",
       "    'mentality_vision',\n",
       "    'mentality_penalties',\n",
       "    'mentality_composure',\n",
       "    'defending_marking',\n",
       "    'defending_standing_tackle',\n",
       "    'defending_sliding_tackle',\n",
       "    'goalkeeping_diving',\n",
       "    'goalkeeping_handling',\n",
       "    'goalkeeping_kicking',\n",
       "    'goalkeeping_positioning',\n",
       "    'goalkeeping_reflexes',\n",
       "    'ls',\n",
       "    'st',\n",
       "    'rs',\n",
       "    'lw',\n",
       "    'lf',\n",
       "    'cf',\n",
       "    'rf',\n",
       "    'rw',\n",
       "    'lam',\n",
       "    'cam',\n",
       "    'ram',\n",
       "    'lm',\n",
       "    'lcm',\n",
       "    'cm',\n",
       "    'rcm',\n",
       "    'rm',\n",
       "    'lwb',\n",
       "    'ldm',\n",
       "    'cdm',\n",
       "    'rdm',\n",
       "    'rwb',\n",
       "    'lb',\n",
       "    'lcb',\n",
       "    'cb',\n",
       "    'rcb',\n",
       "    'rb',\n",
       "    'fifa year',\n",
       "    'national_team',\n",
       "    'seasons_with_club',\n",
       "    'on_loan',\n",
       "    'remaining_seasons_on_contract']),\n",
       "  ('cat_tr',\n",
       "   OneHotEncoder(handle_unknown='ignore'),\n",
       "   ['nationality',\n",
       "    'club_name',\n",
       "    'league_name',\n",
       "    'player_positions',\n",
       "    'preferred_foot',\n",
       "    'work_rate',\n",
       "    'body_type',\n",
       "    'real_face',\n",
       "    'player_tags',\n",
       "    'team_position',\n",
       "    'player_traits'])],\n",
       " 'preprocessing__verbose': False,\n",
       " 'preprocessing__verbose_feature_names_out': True,\n",
       " 'preprocessing__numerics_zero_imputing': Pipeline(steps=[('imputer', SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                 ('scaler', MinMaxScaler())]),\n",
       " 'preprocessing__numerics_mean_imputing': Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler())]),\n",
       " 'preprocessing__cat_tr': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessing__numerics_zero_imputing__memory': None,\n",
       " 'preprocessing__numerics_zero_imputing__steps': [('imputer',\n",
       "   SimpleImputer(fill_value=0, strategy='constant')),\n",
       "  ('scaler', MinMaxScaler())],\n",
       " 'preprocessing__numerics_zero_imputing__verbose': False,\n",
       " 'preprocessing__numerics_zero_imputing__imputer': SimpleImputer(fill_value=0, strategy='constant'),\n",
       " 'preprocessing__numerics_zero_imputing__scaler': MinMaxScaler(),\n",
       " 'preprocessing__numerics_zero_imputing__imputer__add_indicator': False,\n",
       " 'preprocessing__numerics_zero_imputing__imputer__copy': True,\n",
       " 'preprocessing__numerics_zero_imputing__imputer__fill_value': 0,\n",
       " 'preprocessing__numerics_zero_imputing__imputer__missing_values': nan,\n",
       " 'preprocessing__numerics_zero_imputing__imputer__strategy': 'constant',\n",
       " 'preprocessing__numerics_zero_imputing__imputer__verbose': 0,\n",
       " 'preprocessing__numerics_zero_imputing__scaler__clip': False,\n",
       " 'preprocessing__numerics_zero_imputing__scaler__copy': True,\n",
       " 'preprocessing__numerics_zero_imputing__scaler__feature_range': (0, 1),\n",
       " 'preprocessing__numerics_mean_imputing__memory': None,\n",
       " 'preprocessing__numerics_mean_imputing__steps': [('imputer', SimpleImputer()),\n",
       "  ('scaler', MinMaxScaler())],\n",
       " 'preprocessing__numerics_mean_imputing__verbose': False,\n",
       " 'preprocessing__numerics_mean_imputing__imputer': SimpleImputer(),\n",
       " 'preprocessing__numerics_mean_imputing__scaler': MinMaxScaler(),\n",
       " 'preprocessing__numerics_mean_imputing__imputer__add_indicator': False,\n",
       " 'preprocessing__numerics_mean_imputing__imputer__copy': True,\n",
       " 'preprocessing__numerics_mean_imputing__imputer__fill_value': None,\n",
       " 'preprocessing__numerics_mean_imputing__imputer__missing_values': nan,\n",
       " 'preprocessing__numerics_mean_imputing__imputer__strategy': 'mean',\n",
       " 'preprocessing__numerics_mean_imputing__imputer__verbose': 0,\n",
       " 'preprocessing__numerics_mean_imputing__scaler__clip': False,\n",
       " 'preprocessing__numerics_mean_imputing__scaler__copy': True,\n",
       " 'preprocessing__numerics_mean_imputing__scaler__feature_range': (0, 1),\n",
       " 'preprocessing__cat_tr__categories': 'auto',\n",
       " 'preprocessing__cat_tr__drop': None,\n",
       " 'preprocessing__cat_tr__dtype': numpy.float64,\n",
       " 'preprocessing__cat_tr__handle_unknown': 'ignore',\n",
       " 'preprocessing__cat_tr__sparse': True,\n",
       " 'regressor__alpha': 1.0,\n",
       " 'regressor__copy_X': True,\n",
       " 'regressor__fit_intercept': True,\n",
       " 'regressor__l1_ratio': 0.5,\n",
       " 'regressor__max_iter': 1000,\n",
       " 'regressor__normalize': 'deprecated',\n",
       " 'regressor__positive': False,\n",
       " 'regressor__precompute': False,\n",
       " 'regressor__random_state': None,\n",
       " 'regressor__selection': 'cyclic',\n",
       " 'regressor__tol': 0.0001,\n",
       " 'regressor__warm_start': False}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f9a91843",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"preprocessing__numerics_zero_imputing__scaler\": [RobustScaler(), MinMaxScaler(), StandardScaler()],\n",
    "    \"preprocessing__numerics_mean_imputing__scaler\": [RobustScaler(), MinMaxScaler(), StandardScaler()],\n",
    "    'preprocessing__numerics_zero_imputing__imputer__strategy': ['constant', \"mean\"],\n",
    "    'regressor__alpha': [0.01, 0.1, 1], \n",
    "    'regressor__l1_ratio': [0.2, 0.5, 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d482a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95064.80278706708, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57416.62189802307, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28107.682692111106, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.1118658191117, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13173.61696971237, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2693.847847722529, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103409.63749751994, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 113296.20511733851, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3828.001771572948, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29739.42951428803, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 227.52050556614995, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66861.77016650827, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85765.2354016195, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65630.36604475745, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44688.97354773051, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2105.620868291764, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17897.74634135353, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34809.09162215516, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 490.88391804802814, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 115504.31966175429, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25124.952193568068, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.24689240416046, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295.55985235242406, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11375.263502991933, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104593.49431033262, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33315.59573172341, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100828.60623605915, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50453.636342537255, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3714.441618684039, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.70s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29932.34008976673, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107281.68859445729, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104617.11967159538, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1627.0794408418878, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1622.3779865865072, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1342.746540181659, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103246.78688421157, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63776.86972709037, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5429.327632273285, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95211.36095479557, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 477.1728158527112, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39435.6938949968, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290.030950181128, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4137.164145574061, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 222.4806317865441, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104240.42144054477, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15185.79289726881, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190.40735514153494, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20203.74992484784, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.15297226546681, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80818.94516579548, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 545.2344556167664, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 115967.44898943369, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22159.747208575718, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 265.83773949183524, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26147.525805366866, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35463.298209042856, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.67s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114849.40212923207, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 232.53056722076144, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25721.710082644713, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22428.66113760174, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44249.47406675518, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65541.34128045323, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206.63732392404927, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72167.71974718999, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67450.2913079074, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1752.6876245234453, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1705.4218221132178, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.81s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 324.41918308561435, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7418.011062511505, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.74s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22601.67179722173, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 417.6564438715868, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41783.429843355945, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74.24730356544023, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83790.45348733864, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43956.403343561455, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32935.254361652536, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85820.13976391201, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65864.66196769597, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24954.486076294008, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 314.05588443161105, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1662.7106496614288, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13042.799877200508, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.23645651442348, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20537.5148405598, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.59s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33536.61624318636, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.31153079128126, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164.14282366252155, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3275.7189929730084, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116204.5378084411, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11647.716966440465, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88778.29054976942, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47819.243438459205, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24008.394200963754, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31353.94352707322, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89.4074906911701, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1402.7296804428624, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107815.16222125702, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24258.13881607185, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31474.821916642162, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106581.37185301664, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10162.3630450739, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4382.603005346376, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116513.79960434829, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61390.0984180657, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57006.14228687288, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1354.6624876908027, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.94s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 405.3723796395934, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2549.6845344856556, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32540.13585211814, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 471.50011989017366, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114625.39604174587, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 157.1145131852536, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 122242.81383879656, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80904.19695393131, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70654.14818639666, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2605.0775008414057, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.59s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25513.649635282447, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 139.24794966407353, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2996.753884730075, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1633.5710468516918, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 489.84488145585055, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103965.08130175038, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32667.950791627998, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86804.05274561467, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55933.2888627096, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7737.257671038475, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.77s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39170.83749866995, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191.66446868647472, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4474.7806936552515, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5290.157064945088, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29003.32005378304, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103326.96745209927, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23223.867011257506, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 108568.78745344206, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.53s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55416.67280862544, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63627.83296589838, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25738.414257428696, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 1.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21361.5533447146, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.69376004239894, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32140.03954208718, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.83494630703353, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.53s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103086.75526935671, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 762.0104152667045, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.59s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.59s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.53s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79757.42181622534, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56230.74697877329, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3966.0596144222363, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 740.8115622673358, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3002.2445517862798, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28262.249952774917, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 115396.34403921285, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107727.64321982619, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37615.78053764811, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161.52247379012988, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.56s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28600.549641856953, tolerance: 38.46358726540298\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 111179.34603126498, tolerance: 43.09857716086318\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23005.64537933303, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4213.791339122719, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30462.629363779502, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 142.37845934415236, tolerance: 38.35979237369807\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.55s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106974.4957798819, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25624.46966150061, tolerance: 35.19744013692684\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171.5990621217352, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/alexpins/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30365.723257804377, tolerance: 38.47031618782792\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessing__numerics_mean_imputing__scaler': StandardScaler(), 'preprocessing__numerics_zero_imputing__imputer__strategy': 'mean', 'preprocessing__numerics_zero_imputing__scaler': StandardScaler(), 'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.2}\n",
      "0.33531911844772627\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
